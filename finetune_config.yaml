# 微调配置文件
model:
  base_model: "Qwen/Qwen2-7B-Instruct"  # 基础模型
  # 或者使用其他开源模型如：
  # - "microsoft/DialoGPT-medium"
  # - "THUDM/chatglm3-6b"
  # - "baichuan-inc/Baichuan2-7B-Chat"

training:
  # 数据路径
  train_file: "finetune_data/train.jsonl"
  validation_file: "finetune_data/val.jsonl"
  
  # 训练参数
  num_train_epochs: 3
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 2
  
  # 学习率
  learning_rate: 2e-5
  warmup_steps: 100
  
  # 优化器
  optim: "adamw_torch"
  weight_decay: 0.01
  
  # 保存和评估
  save_steps: 500
  eval_steps: 500
  save_total_limit: 3
  
  # 日志
  logging_steps: 100
  report_to: "tensorboard"
  
  # 输出目录
  output_dir: "spatial_reasoning_model"
  
  # 其他设置
  remove_unused_columns: false
  dataloader_pin_memory: false
  bf16: true  # 使用混合精度训练
  gradient_checkpointing: true  # 节省显存
  
  # 早停
  early_stopping_patience: 3
  early_stopping_threshold: 0.001

# LoRA配置（如果使用LoRA）
lora:
  r: 16
  lora_alpha: 32
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

# 数据格式
data_format:
  type: "chatml"  # 或 "alpaca", "sharegpt"
  system_prompt: "你是一个空间推理专家..." 